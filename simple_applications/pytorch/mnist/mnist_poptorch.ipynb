{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1ceb9b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright (c) 2020 Graphcore Ltd. All rights reserved."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98ac4804",
   "metadata": {},
   "source": [
    "# PyTorch(PopTorch) MNIST Training Demo\n",
    "\n",
    "This example demonstrates how to train a network on the MNIST dataset using\n",
    "PopTorch."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35dfb768",
   "metadata": {},
   "source": [
    "## How to use this demo\n",
    "\n",
    "1) Prepare the environment.\n",
    "\n",
    "Install the Poplar SDK following the instructions in the Getting Started guide \n",
    "for your IPU system. Make sure to run the `enable.sh` scripts for Poplar and \n",
    "PopART and activate a Python virtualenv with PopTorch installed.\n",
    "\n",
    "Then install the package requirements:\n",
    "```bash\n",
    "pip install -r requirements.txt\n",
    "```\n",
    "\n",
    "2) Run the program. Note that the PopTorch Python API only supports Python 3.\n",
    "Data will be automatically downloaded using torchvision utils.\n",
    "\n",
    "```bash\n",
    "python3 mnist_poptorch.py\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40a36eb6",
   "metadata": {},
   "source": [
    "Select your hyperparameters in this cell. If you wish to modify them, re-run\n",
    "all cells below it. Further reading [Hyperparameters](https://en.wikipedia.org/wiki/Hyperparameter_(machine_learning))\n",
    "Setup parameters for training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9047c1e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Batch size for training\n",
    "batch_size = 8\n",
    "\n",
    "# Device iteration - batches per step\n",
    "batches_per_step = 50\n",
    "\n",
    "# Batch size for testing\n",
    "test_batch_size = 80\n",
    "\n",
    "# Number of epochs to train\n",
    "epochs = 10\n",
    "\n",
    "# Learning rate\n",
    "learning_rate = 0.05"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26c132cb",
   "metadata": {},
   "source": [
    "Import required libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0761604",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import poptorch\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cdb392b",
   "metadata": {},
   "source": [
    "Download the datasets for MNIST - database for handwritten digits.\n",
    "Source: [The MNIST Database](http://yann.lecun.com/exdb/mnist/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff1404d4",
   "metadata": {
    "tags": [
     "sst_hide_output"
    ]
   },
   "outputs": [],
   "source": [
    "# The following is a workaround for pytorch issue #1938\n",
    "from six.moves import urllib\n",
    "opener = urllib.request.build_opener()\n",
    "opener.addheaders = [(\"User-agent\", \"Mozilla/5.0\")]\n",
    "urllib.request.install_opener(opener)\n",
    "\n",
    "local_dataset_path = 'mnist_data/'\n",
    "\n",
    "transform_mnist = torchvision.transforms.Compose(\n",
    "    [\n",
    "        torchvision.transforms.ToTensor(),\n",
    "        torchvision.transforms.Normalize((0.1307, ), (0.3081, ))\n",
    "    ]\n",
    ")\n",
    "\n",
    "training_dataset = torchvision.datasets.MNIST(\n",
    "        local_dataset_path,\n",
    "        train=True,\n",
    "        download=True,\n",
    "        transform=transform_mnist\n",
    ")\n",
    "\n",
    "training_data = torch.utils.data.DataLoader(\n",
    "    training_dataset,\n",
    "    batch_size=batch_size * batches_per_step,\n",
    "    shuffle=True,\n",
    "    drop_last=True\n",
    ")\n",
    "\n",
    "test_dataset = torchvision.datasets.MNIST(\n",
    "        local_dataset_path,\n",
    "        train=False,\n",
    "        download=True,\n",
    "        transform=transform_mnist\n",
    ")\n",
    "\n",
    "test_data = torch.utils.data.DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=test_batch_size,\n",
    "    shuffle=True,\n",
    "    drop_last=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "991ca8c5",
   "metadata": {},
   "source": [
    "Let's define the elements of our neural network. First, we create the class\n",
    "`Block` which will consist of a simple 2D convolutional layer with pooling and\n",
    "a rectified linear unit (ReLU). To see explanation of pooling and ReLU, see:\n",
    "[Convolutional Neural Network](https://en.wikipedia.org/wiki/Convolutional_neural_network#Building_blocks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e862bbf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Block(nn.Module):\n",
    "    def __init__(self, in_channels, num_filters, kernel_size, pool_size):\n",
    "        super(Block, self).__init__()\n",
    "        self.conv = nn.Conv2d(in_channels,\n",
    "                              num_filters,\n",
    "                              kernel_size=kernel_size)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=pool_size)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = self.pool(x)\n",
    "        x = self.relu(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b4affa6",
   "metadata": {},
   "source": [
    "Now let's construct the deep neural network with 4 Convolutional layers and\n",
    "a [softmax layer](https://en.wikipedia.org/wiki/Softmax_function) at the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac58364a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Network, self).__init__()\n",
    "        self.layer1 = Block(1, 32, 3, 2)\n",
    "        self.layer2 = Block(32, 64, 3, 2)\n",
    "        self.layer3 = nn.Linear(1600, 128)\n",
    "        self.layer3_act = nn.ReLU()\n",
    "        self.layer3_dropout = torch.nn.Dropout(0.5)\n",
    "        self.layer4 = nn.Linear(128, 10)\n",
    "        self.softmax = nn.Softmax(1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        # Flatten layer\n",
    "        x = x.view(-1, 1600)\n",
    "        x = self.layer3_act(self.layer3(x))\n",
    "        x = self.layer4(self.layer3_dropout(x))\n",
    "        x = self.softmax(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "550af1b2",
   "metadata": {},
   "source": [
    "Here we define a thin wrapper around the `torch.nn.Module` that will use\n",
    "cross-entropy loss function - see more [here](https://en.wikipedia.org/wiki/Cross_entropy#Cross-entropy_loss_function_and_logistic_regression)\n",
    "\n",
    "This class is creating a custom module to compose the Neural Network and \n",
    "the Cross Entropy module into one object, which under the hood will invoke \n",
    "the `__call__` function on `nn.Module` and consequently the `forward` method \n",
    "when called like this:\n",
    "```python\n",
    "prediction, losses = TrainingModelWithLoss(Network())(data, labels)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e21e27bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainingModelWithLoss(torch.nn.Module):\n",
    "    def __init__(self, model):\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "        self.loss = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "    def forward(self, args, loss_inputs=None):\n",
    "        output = self.model(args)\n",
    "        loss = self.loss(output, loss_inputs)\n",
    "        return output, loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eaed88f",
   "metadata": {},
   "source": [
    "Let's initiate the neural network from our defined classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f691774",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Network()\n",
    "model_with_loss = TrainingModelWithLoss(model)\n",
    "model_opts = poptorch.Options().deviceIterations(batches_per_step)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e34b21b2",
   "metadata": {},
   "source": [
    "We can check if the model is assembled correctly by printing the string \n",
    "representation of the model object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b49162e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model_with_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4adf7edb",
   "metadata": {},
   "source": [
    "Now we apply the model wrapping function, which will perform a shallow copy\n",
    "of the PyTorch model. To perform the machine learning operations, we also\n",
    "will use the Stochastic Gradient Descent with no momentum [SGD](https://docs.graphcore.ai/projects/poptorch-user-guide/en/latest/reference.html#poptorch.optim.SGD)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f84cd6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_model = poptorch.trainingModel(\n",
    "    model_with_loss,\n",
    "    model_opts,\n",
    "    optimizer=optim.SGD(model.parameters(), lr=learning_rate)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fe8e9ac",
   "metadata": {},
   "source": [
    "We are ready to start training. However to track the accuracy while training\n",
    "we need to define one more helper function. During the training, not every \n",
    "samples prediction is returned for efficiency reasons, so this helper function\n",
    "will check accuracy for labels where prediction is available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12f2ade1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(predictions, labels):\n",
    "    _, ind = torch.max(predictions, 1)\n",
    "    labels = labels[-predictions.size()[0]:]\n",
    "    accuracy = \\\n",
    "        torch.sum(torch.eq(ind, labels)).item() / labels.size()[0] * 100.0\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf53fba2",
   "metadata": {},
   "source": [
    "This code will perform the requested amount of epochs and batches using the\n",
    "configured Graphcore IPUs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a24be9e9",
   "metadata": {
    "tags": [
     "sst_hide_output"
    ]
   },
   "outputs": [],
   "source": [
    "nr_batches = len(training_data)\n",
    "\n",
    "for epoch in tqdm(range(1, epochs+1), leave=True, desc=\"Epochs\", total=epochs):\n",
    "    with tqdm(training_data, total=nr_batches, leave=False) as bar:\n",
    "        for data, labels in bar:\n",
    "            preds, losses = training_model(data, labels)\n",
    "            with torch.inference_mode():\n",
    "                mean_loss = torch.mean(losses).item()\n",
    "                acc = accuracy(preds, labels)\n",
    "            bar.set_description(\n",
    "                \"Loss: {:0.4f} | Accuracy: {:05.2F}% \".format(mean_loss, acc)\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1acd4c80",
   "metadata": {},
   "source": [
    "Update the weights in model by copying from the training IPU. \n",
    "This updates `model.parameters()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a86bf51",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_model.copyWeightsToHost()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0053b6e5",
   "metadata": {},
   "source": [
    "Release resources:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abc664d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_model.detachFromDevice()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42b79970",
   "metadata": {},
   "source": [
    "Check validation loss on IPU once trained. Because PopTorch will be compiled \n",
    "on first call the weights in `model.parameters()` will be copied implicitly. \n",
    "Subsequent calls will need to call `inference_model.copyWeightsToDevice()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0027c0db",
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_model = poptorch.inferenceModel(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "507e87cb",
   "metadata": {},
   "source": [
    "Perform validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6728027",
   "metadata": {
    "tags": [
     "sst_hide_output"
    ]
   },
   "outputs": [],
   "source": [
    "nr_batches = len(test_data)\n",
    "sum_acc = 0.0\n",
    "with torch.no_grad():\n",
    "    with tqdm(test_data, total=nr_batches, leave=False) as bar:\n",
    "        for data, labels in bar:\n",
    "            output = inference_model(data)\n",
    "            sum_acc += accuracy(output, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e48e777",
   "metadata": {},
   "source": [
    "Finally the accuracy on the test set is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dd78be6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Accuracy on test set: {:0.2f}%\".format(sum_acc / len(test_data)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8be5960c",
   "metadata": {},
   "source": [
    "Release resources:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49569dd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_model.detachFromDevice()"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
