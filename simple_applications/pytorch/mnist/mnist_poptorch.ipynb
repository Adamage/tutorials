{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3b155370",
   "metadata": {},
   "source": [
    "Copyright (c) 2020 Graphcore Ltd. All rights reserved."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "722f7cc4",
   "metadata": {},
   "source": [
    "# PyTorch(PopTorch) MNIST Training Demo\n",
    "\n",
    "This example demonstrates how to train a network on the MNIST dataset using\n",
    "PopTorch. To learn more about PopTorch, see our [PyTorch for the IPU: User Guide](https://docs.graphcore.ai/projects/poptorch-user-guide/en/latest/index.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37eb970b",
   "metadata": {},
   "source": [
    "## How to use this demo\n",
    "\n",
    "### 1) Prepare the environment.\n",
    "\n",
    "Install the Poplar SDK following the instructions in the [Getting Started](https://docs.graphcore.ai/en/latest/getting-started.html)\n",
    "guide for your IPU system. Make sure to run the `enable.sh` scripts for Poplar \n",
    "and PopART and activate a Python3 virtualenv with PopTorch installed.\n",
    "\n",
    "Then install the package requirements:\n",
    "```bash\n",
    "pip install -r requirements.txt\n",
    "```\n",
    "\n",
    "### 2) Run the program. \n",
    "Note that the PopTorch Python API only supports Python 3. Data will be \n",
    "automatically downloaded using torchvision utils.\n",
    "\n",
    "```bash\n",
    "python3 mnist_poptorch.py\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c5c2e47",
   "metadata": {},
   "source": [
    "### 3) Hyperparameters\n",
    "Set the hyperparameters for this demo. If you're running this example in \n",
    "a Jupyter notebook and wish to modify them, re-run all the cells below.\n",
    "For further reading on hyperparameters, see [Hyperparameters (machine learning)](https://en.wikipedia.org/wiki/Hyperparameter_(machine_learning))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "358ee788",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Batch size for training\n",
    "batch_size = 8\n",
    "\n",
    "# Device iteration - batches per step. Number of iterations the device should\n",
    "# run over the data before returning to the user.\n",
    "# This is equivalent to running the IPU in a loop over that the specified\n",
    "# number of iterations, with a new batch of data each time. However, increasing\n",
    "# deviceIterations is more efficient because the loop runs on the IPU directly.\n",
    "device_iterations = 50\n",
    "\n",
    "# Batch size for testing\n",
    "test_batch_size = 80\n",
    "\n",
    "# Number of epochs to train\n",
    "epochs = 10\n",
    "\n",
    "# Learning rate\n",
    "learning_rate = 0.03"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1afe96e",
   "metadata": {},
   "source": [
    "Import required libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c2d0be1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import poptorch\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0571300",
   "metadata": {},
   "source": [
    "Download the datasets for MNIST and set up data loaders.\n",
    "Source: [The MNIST Database](http://yann.lecun.com/exdb/mnist/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "887424f7",
   "metadata": {
    "tags": [
     "sst_hide_output"
    ]
   },
   "outputs": [],
   "source": [
    "local_dataset_path = '~/.torch/datasets'\n",
    "\n",
    "transform_mnist = torchvision.transforms.Compose(\n",
    "    [\n",
    "        torchvision.transforms.ToTensor(),\n",
    "        torchvision.transforms.Normalize((0.1307, ), (0.3081, ))\n",
    "    ]\n",
    ")\n",
    "\n",
    "training_dataset = torchvision.datasets.MNIST(\n",
    "        local_dataset_path,\n",
    "        train=True,\n",
    "        download=True,\n",
    "        transform=transform_mnist\n",
    ")\n",
    "\n",
    "training_data = torch.utils.data.DataLoader(\n",
    "    training_dataset,\n",
    "    batch_size=batch_size * device_iterations,\n",
    "    shuffle=True,\n",
    "    drop_last=True\n",
    ")\n",
    "\n",
    "test_dataset = torchvision.datasets.MNIST(\n",
    "        local_dataset_path,\n",
    "        train=False,\n",
    "        download=True,\n",
    "        transform=transform_mnist\n",
    ")\n",
    "\n",
    "test_data = torch.utils.data.DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=test_batch_size,\n",
    "    shuffle=True,\n",
    "    drop_last=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "456c5d32",
   "metadata": {},
   "source": [
    "Let's define the elements of our neural network. We first create a `Block`\n",
    "instance consisting of a 2D convolutional layer with pooling, followed by\n",
    "a ReLU activation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9921651",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Block(nn.Module):\n",
    "    def __init__(self, in_channels, num_filters, kernel_size, pool_size):\n",
    "        super(Block, self).__init__()\n",
    "        self.conv = nn.Conv2d(in_channels,\n",
    "                              num_filters,\n",
    "                              kernel_size=kernel_size)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=pool_size)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = self.pool(x)\n",
    "        x = self.relu(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c539efc",
   "metadata": {},
   "source": [
    "Now, let's construct our neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc812e98",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Network, self).__init__()\n",
    "        self.layer1 = Block(1, 32, 3, 2)\n",
    "        self.layer2 = Block(32, 64, 3, 2)\n",
    "        self.layer3 = nn.Linear(1600, 128)\n",
    "        self.layer3_act = nn.ReLU()\n",
    "        self.layer3_dropout = torch.nn.Dropout(0.5)\n",
    "        self.layer4 = nn.Linear(128, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        # Flatten layer\n",
    "        x = x.view(-1, 1600)\n",
    "        x = self.layer3_act(self.layer3(x))\n",
    "        x = self.layer4(self.layer3_dropout(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66d73ed9",
   "metadata": {},
   "source": [
    "Next we define a thin wrapper around the `torch.nn.Module` that will use\n",
    "the cross-entropy loss function. To learn more about cross entropy click [here](https://en.wikipedia.org/wiki/Cross_entropy#Cross-entropy_loss_function_and_logistic_regression).\n",
    "\n",
    "This class is creating a custom module to compose the Neural Network and \n",
    "the Cross Entropy module into one object, which under the hood will invoke \n",
    "the `__call__` function on `nn.Module` and consequently the `forward` method \n",
    "when called like this:\n",
    "```python\n",
    "prediction, losses = TrainingModelWithLoss(Network())(data, labels)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "037839f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainingModelWithLoss(torch.nn.Module):\n",
    "    def __init__(self, model):\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "        self.loss = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "    def forward(self, args, loss_inputs=None):\n",
    "        output = self.model(args)\n",
    "        loss = self.loss(output, loss_inputs)\n",
    "        return output, loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0443517f",
   "metadata": {},
   "source": [
    "Let's initialise the neural network from our defined classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67cdcbc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Network()\n",
    "model_with_loss = TrainingModelWithLoss(model)\n",
    "model_opts = poptorch.Options().deviceIterations(device_iterations)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5595b7fb",
   "metadata": {},
   "source": [
    "Next we will set the `AnchorMode` for our training. By default, `poptorch` will\n",
    "return to the host machine only a limited set of information for performance\n",
    "reasons. By default, only the last batch of the internal loop is returned which\n",
    "is represented by setting `AnchorMode.Final`. When inspecting the training\n",
    "performance as it is executing, values like accuracy or losses value will be\n",
    "then calculated only for that last batch, specifically the `batch_size` out of\n",
    "the whole step which is `batch_size*device_iterations`.\n",
    "We can set this to `AnchorMode.All` to be able to present the full information.\n",
    "This has an impact on the speed of training, due to overhead of transferring\n",
    "more data to the host machine.\n",
    "For further reading on all of the modes please read [`AnchorMode` documentation](https://docs.graphcore.ai/projects/poptorch-user-guide/en/latest/reference.html?highlight=anchorMode#poptorch.Options.anchorMode)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44726812",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_opts = model_opts.anchorMode(poptorch.AnchorMode.All)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d4e2e31",
   "metadata": {},
   "source": [
    "We can check if the model is assembled correctly by printing the string \n",
    "representation of the model object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0cd5d84",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model_with_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "446fddc2",
   "metadata": {},
   "source": [
    "Now we apply the model wrapping function, which will perform a shallow copy\n",
    "of the PyTorch model. To train the model we will use the Stochastic Gradient \n",
    "Descent with no momentum [SGD](https://docs.graphcore.ai/projects/poptorch-user-guide/en/latest/reference.html#poptorch.optim.SGD)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b6f5f21",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_model = poptorch.trainingModel(\n",
    "    model_with_loss,\n",
    "    model_opts,\n",
    "    optimizer=optim.SGD(model.parameters(), lr=learning_rate)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61b030b8",
   "metadata": {},
   "source": [
    "We are ready to start training. However to track the accuracy while training\n",
    "we need to define one more helper function. During the training, not every \n",
    "samples prediction is returned for efficiency reasons, so this helper function\n",
    "will check accuracy for labels where prediction is available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c036fb48",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(predictions, labels):\n",
    "    _, ind = torch.max(predictions, 1)\n",
    "    labels = labels[-predictions.size()[0]:]\n",
    "    accuracy = \\\n",
    "        torch.sum(torch.eq(ind, labels)).item() / labels.size()[0] * 100.0\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c86099d",
   "metadata": {},
   "source": [
    "This code will perform the requested amount of epochs and batches using the\n",
    "configured Graphcore IPUs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7fcd6f5",
   "metadata": {
    "tags": [
     "sst_hide_output"
    ]
   },
   "outputs": [],
   "source": [
    "nr_batches = len(training_data)\n",
    "\n",
    "for epoch in tqdm(range(1, epochs+1), leave=True, desc=\"Epochs\", total=epochs):\n",
    "    with tqdm(training_data, total=nr_batches, leave=False) as bar:\n",
    "        for data, labels in bar:\n",
    "            preds, losses = training_model(data, labels)\n",
    "\n",
    "            mean_loss = torch.mean(losses).item()\n",
    "\n",
    "            acc = accuracy(preds, labels)\n",
    "            bar.set_description(\n",
    "                \"Loss: {:0.4f} | Accuracy: {:05.2F}% \".format(mean_loss, acc)\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffcb5845",
   "metadata": {},
   "source": [
    "Release resources:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d88c44bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_model.detachFromDevice()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "973f4b2b",
   "metadata": {},
   "source": [
    "Let's check the validation loss on IPU using the trained model. The weights \n",
    "in `model.parameters()` will be copied from the IPU to the host. The weights\n",
    "from the trained model will be reused to compile the new inference model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b1275dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_model = poptorch.inferenceModel(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa3caeeb",
   "metadata": {},
   "source": [
    "Perform validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab1d525f",
   "metadata": {
    "tags": [
     "sst_hide_output"
    ]
   },
   "outputs": [],
   "source": [
    "nr_batches = len(test_data)\n",
    "sum_acc = 0.0\n",
    "with tqdm(test_data, total=nr_batches, leave=False) as bar:\n",
    "    for data, labels in bar:\n",
    "        output = inference_model(data)\n",
    "        sum_acc += accuracy(output, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96b1b2c6",
   "metadata": {},
   "source": [
    "Finally the accuracy on the test set is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fb2579c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Accuracy on test set: {:0.2f}%\".format(sum_acc / len(test_data)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90536ed0",
   "metadata": {},
   "source": [
    "Release resources:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f251a377",
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_model.detachFromDevice()"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
